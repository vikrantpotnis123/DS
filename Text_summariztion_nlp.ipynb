{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_summariztion_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOlornXmZPlVo1U39LfcW6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikrantpotnis123/DS/blob/master/Text_summariztion_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv1jKYKyRL25",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing of corpus\n",
        "Steps include\n",
        "- text lower casing\n",
        "- special chars removal\n",
        "- generate list of sentences by splitting text\n",
        "- generate list of words by splitting sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f530b43-6553-4201-ac4f-8776a92bc886"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsfFS2hjRnZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "e82a1a2e-adf0-4096-905a-752088ca80d3"
      },
      "source": [
        "!pip install spacy\n",
        "!pip install beautifulsoup4\n",
        "!pip install lxml"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhOJQHynSDft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e9ba726e-9eee-44ca-c4d7-5bf8b617a2bf"
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BLKofzadbdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summarize_text(sentence_score):\n",
        "  import heapq\n",
        "  summary_sentences = heapq.nlargest(7, sentence_score, key=sentence_score.get)\n",
        "  summary = ' '.join(summary_sentences)\n",
        "  pp.pprint(summary)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juFfdN95og58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_sentence_score(word_freqs, list_of_sentences):\n",
        "  sentence_score = {}\n",
        "  # generate pairs of (sentence, sum of word freqs of words in the sentence)\n",
        "  for sentence in list_of_sentences:\n",
        "    for word in nltk.word_tokenize(sentence.lower()):\n",
        "      if word in word_freqs.keys() and len(sentence.split())  < 30:\n",
        "        if sentence not in sentence_score.keys():\n",
        "          sentence_score[sentence] = word_freqs[word]\n",
        "        else:\n",
        "          sentence_score[sentence] += word_freqs[word]\n",
        "  return sentence_score"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv00V0PWoFQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_word_freqs(word_tokens, stop_words):\n",
        "  word_freqs = {}\n",
        "  for word in word_tokens:\n",
        "    if word not in stop_words:\n",
        "      if word not in word_freqs.keys():\n",
        "        word_freqs[word] = 1\n",
        "      else:\n",
        "        word_freqs[word] += 1\n",
        "\n",
        "  max_word_freq = max(word_freqs.values())\n",
        "  for word in word_freqs:\n",
        "    word_freqs[word] /= max_word_freq\n",
        "  return word_freqs"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrrLXeYZlfX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_tokens(wiki_text, formatted_wiki_text):\n",
        "  word_tokens = nltk.word_tokenize(formatted_wiki_text)\n",
        "  stop_words = nltk.corpus.stopwords.words('english')\n",
        "  list_of_sentences = nltk.sent_tokenize(wiki_text)\n",
        "  return word_tokens, stop_words, list_of_sentences\n"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3NtMahDnr3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_wiki(url):\n",
        "  wiki_data =  urllib.request.urlopen(url)\n",
        "  wiki_page = wiki_data.read()\n",
        "  parsed_wiki = bs.BeautifulSoup(wiki_page, 'lxml')\n",
        "  paras = parsed_wiki.find_all('p')\n",
        "  wiki_text = \"\"\n",
        "  for p in paras:\n",
        "    wiki_text += p.text\n",
        "    \n",
        "  # Remove square brackets, extra spaces\n",
        "  wiki_text = re.sub(r'\\[[0-9]*\\]', ' ', wiki_text)\n",
        "  wiki_text = re.sub(r'\\s+', ' ', wiki_text)\n",
        "\n",
        "  # Removing special characters and digits\n",
        "  formatted_wiki_text = re.sub('[^a-zA-Z]', ' ', wiki_text )\n",
        "  formatted_wiki_text = re.sub(r'\\s+', ' ', formatted_wiki_text)\n",
        "  return wiki_text, formatted_wiki_text"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QPhFovSmUG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wiki_summary(url):\n",
        "  print()\n",
        "  wiki_text, formatted_wiki_text = parse_wiki(url)\n",
        "  word_tokens, stop_words, list_of_sentences = gen_tokens(wiki_text, formatted_wiki_text)\n",
        "  word_freqs = gen_word_freqs(word_tokens, stop_words)\n",
        "  sentence_score = gen_sentence_score(word_freqs, list_of_sentences)\n",
        "  summarize_text(sentence_score)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNPA5fczmFch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5027a2a-dbb1-4cab-859c-d1d5b8c37daf"
      },
      "source": [
        "wiki_summary('https://en.wikipedia.org/wiki/German_Shepherd')\n",
        "wiki_summary('https://en.wikipedia.org/wiki/Dinosaur')\n",
        "wiki_summary('https://en.wikipedia.org/wiki/World_War_I')\n",
        "wiki_summary('https://en.wikipedia.org/wiki/Artificial_intelligence')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "('Horand was declared to be the first German Shepherd Dog and was the first '\n",
            " \"dog added to the society's breed register. He admired the intelligence, \"\n",
            " \"strength and ability of Germany's native sheepdogs, but could not find any \"\n",
            " 'one single breed that satisfied him as the perfect working dog. Nevertheless '\n",
            " 'it became one of the staple productions of Hungarian television history, '\n",
            " 'making German Shepherds the most popular dog breed in the country ever '\n",
            " 'since. Degenerative myelopathy, a neurological disease, occurs with enough '\n",
            " 'regularity specifically in the breed to suggest that the breed is '\n",
            " 'predisposed to it. The German Shepherd is the second-most registered breed '\n",
            " 'by the American Kennel Club and seventh-most registered breed by The Kennel '\n",
            " 'Club in the United Kingdom. At one time the German Shepherd was the breed '\n",
            " 'chosen almost exclusively to be used as a guide dog for the visually '\n",
            " 'impaired. The Kennel Club, in the United Kingdom, is involved in a dispute '\n",
            " 'with German Shepherd breed clubs about the issue of soundness in the '\n",
            " 'show-strain of the breed.')\n",
            "\n",
            "('Dinosaurs can therefore be divided into avian dinosaurs, or birds; and '\n",
            " 'non-avian dinosaurs, which are all dinosaurs other than birds. Since the '\n",
            " '1990s, a number of additional feathered dinosaurs have been found, providing '\n",
            " 'even stronger evidence of the close relationship between dinosaurs and '\n",
            " 'modern birds. Because feathers are often associated with birds, feathered '\n",
            " 'dinosaurs are often touted as the missing link between birds and dinosaurs. '\n",
            " 'Comparisons between the scleral rings of dinosaurs and modern birds and '\n",
            " 'reptiles have been used to infer daily activity patterns of dinosaurs. '\n",
            " 'However, all non-avian dinosaurs, estimated to have been 628-1078 species, '\n",
            " 'as well as many groups of birds did suddenly become extinct approximately 66 '\n",
            " 'million years ago. Through the first half of the 20th century, before birds '\n",
            " 'were recognized to be dinosaurs, most of the scientific community believed '\n",
            " 'dinosaurs to have been sluggish and cold-blooded. Paleontologists think that '\n",
            " 'Eoraptor resembles the common ancestor of all dinosaurs; if this is true, '\n",
            " 'its traits suggest that the first dinosaurs were small, bipedal predators.')\n",
            "\n",
            "('After World War II began in 1939, the terms became more standard, with '\n",
            " 'British Empire historians, including Canadians, favouring \"The First World '\n",
            " 'War\" and Americans \"World War I\". Contemporary Europeans also referred to it '\n",
            " 'as \"the war to end war\" or \"the war to end all wars\" due to their perception '\n",
            " 'of its then-unparalleled scale and devastation. When the war began, however, '\n",
            " 'it declared its neutrality, arguing that because Austria-Hungary had itself '\n",
            " 'declared war on Serbia, Romania was under no obligation to join the war. '\n",
            " 'Prior to World War II, the events of 1914â€“1918 were generally known as the '\n",
            " 'Great War or simply the World War. After the war, the Paris Peace Conference '\n",
            " 'imposed a series of peace treaties on the Central Powers officially ending '\n",
            " 'the war. Benedict XV, elected to the papacy less than three months into '\n",
            " 'World War I, made the war and its consequences the main focus of his early '\n",
            " 'pontificate. World War II was in part a continuation of the power struggle '\n",
            " 'never fully resolved by World War I.')\n",
            "\n",
            "(' In computer science, artificial intelligence (AI), sometimes called machine '\n",
            " 'intelligence, is intelligence demonstrated by machines, unlike the natural '\n",
            " 'intelligence displayed by humans and animals. Neural networks can be applied '\n",
            " 'to the problem of intelligent control (for robotics) or learning, using such '\n",
            " 'techniques as Hebbian learning (\"fire together, wire together\"), GMDH or '\n",
            " 'competitive learning. Musk also funds companies developing artificial '\n",
            " 'intelligence such as DeepMind and Vicarious to \"just keep an eye on what\\'s '\n",
            " 'going on with artificial intelligence. Many of the problems in this article '\n",
            " 'may also require general intelligence, if machines are to solve the problems '\n",
            " 'as well as people do. IBM has created its own artificial intelligence '\n",
            " 'computer, the IBM Watson, which has beaten human intelligence (at some '\n",
            " 'levels). \"robotics\" or \"machine learning\"), the use of particular tools '\n",
            " '(\"logic\" or artificial neural networks), or deep philosophical differences. '\n",
            " 'A superintelligence, hyperintelligence, or superhuman intelligence is a '\n",
            " 'hypothetical agent that would possess intelligence far surpassing that of '\n",
            " 'the brightest and most gifted human mind.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFWEUurZmtE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 156,
      "outputs": []
    }
  ]
}