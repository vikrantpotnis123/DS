{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tut1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnJGLubtYqC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "86e6cb58-4f8e-459b-bc35-9945b8e4e1ee"
      },
      "source": [
        "#This tutorial runs pytorch neural network example\n",
        "import torch\n",
        "\n",
        "# Use torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.randn(N, D_in, device=torch.device(\"cpu\"), dtype=torch.float) # vs np.random.randn(N, D_in)\n",
        "y = torch.randn(N, D_out, device=torch.device(\"cpu\"), dtype=torch.float)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = torch.randn(D_in, H, device=torch.device(\"cpu\"), dtype=torch.float)\n",
        "w2 = torch.randn(H, D_out, device=torch.device(\"cpu\"), dtype=torch.float)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.mm(w1) # vs h = x.dot(w1)\n",
        "    h_relu = h.clamp(min=0) # vs h_relu = np.maximum(h, 0)\n",
        "    y_pred = h_relu.mm(w2) # vs  y_pred = h_relu.dot(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item() # vs loss = np.square(y_pred - y).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_w2 = h_relu.t().mm(grad_y_pred) # vs grad_w2 = h_relu.T.dot(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.mm(w2.t()) # vs grad_y_pred.dot(w2.T)\n",
        "    grad_h = grad_h_relu.clone() # vs grad_h_relu.copy()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.t().mm(grad_h) # vs grad_w1 = x.T.dot(grad_h)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 612.0463256835938\n",
            "199 4.462260723114014\n",
            "299 0.05373704433441162\n",
            "399 0.0010010827099904418\n",
            "499 9.729719022288918e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPymmRjdY0c6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "70c71d9d-b4a4-4a02-fb6d-fdb56e68f395"
      },
      "source": [
        "#This tutorial runs neural network example using numpy and without pytorch\n",
        "import numpy as np\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random input and output data\n",
        "x = np.random.randn(N, D_in)\n",
        "y = np.random.randn(N, D_out)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = np.random.randn(D_in, H)\n",
        "w2 = np.random.randn(H, D_out)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.dot(w1)\n",
        "    h_relu = np.maximum(h, 0)\n",
        "    y_pred = h_relu.dot(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = np.square(y_pred - y).sum()\n",
        "    if t % 100 == 99:\n",
        "      print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
        "    grad_h = grad_h_relu.copy()\n",
        "    grad_h[h < 0] = 0 # for all -ve h set grad_h to zero\n",
        "    grad_w1 = x.T.dot(grad_h)\n",
        "\n",
        "    # Update weights\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 971.217399355822\n",
            "199 5.3713751270405234\n",
            "299 0.0439001185282819\n",
            "399 0.0004454981077200312\n",
            "499 5.2531391249588826e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJi2gUuqYKvK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d8cf7f68-e63c-4b20-a0c5-351476db60bb"
      },
      "source": [
        "# This tutorial shows how to subclass nn.Module to define a custom CNN class\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8HmfFnUs2eq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "a4a636c0-155c-4371-ec2f-7d3a0547cc27"
      },
      "source": [
        "# This tutorial how to use torch.autograd and torch.nn to build neural network\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Linear\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "dtype = torch.float\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "#define model\n",
        "model = torch.nn.Sequential (\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out)\n",
        ")\n",
        "#loss fn\n",
        "loss_fn  = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for i in range(500):\n",
        "  # do forward prop\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # calculate loss \n",
        "  loss = loss_fn(y_pred, y)\n",
        "\n",
        "  # print loss\n",
        "  if i % 100 == 0:\n",
        "    print(i, loss.item())\n",
        "\n",
        "  # zero the grads out\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # compute grad of loss w.r.t all learnable model params\n",
        "  loss.backward() \n",
        "\n",
        "  # update the learnable params\n",
        "  optimizer.step()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 625.8773803710938\n",
            "100 3.5260252952575684\n",
            "200 0.06934116780757904\n",
            "300 0.001994086429476738\n",
            "400 6.989714893279597e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJR7mLzw_OPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "576eb0f2-9026-4840-ef92-6ea443b907de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#uploaded = files.upload()\n",
        "#df2 = pd.read_csv(io.BytesIO(uploaded['wine.csv']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjTagG61SvUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MyWineDataset('wine.csv')\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "#load whole dataset with dataloader\n",
        "# batch size is 4\n",
        "# shuffle\n",
        "# num workers\n",
        "\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, \n",
        "                         shuffle=True, num_workers=2)\n",
        "\n",
        "#convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = dataiter.next()\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "\n",
        "# dummy training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/batch_size)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, labels) in enumerate(train_loader):\n",
        "    if ((i+1)%5 == 0):\n",
        "      print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFUPtr239GM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load some famous datasets\n",
        "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
        "\n",
        "\n",
        "famous_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "\n",
        "batch_size = 4\n",
        "train_loader2 = DataLoader(dataset=famous_dataset, batch_size=batch_size, \n",
        "                         shuffle=True, num_workers=2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ljF2b84DUxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load a random sample\n",
        "dataiter2 = iter(train_loader2)\n",
        "data2 = dataiter2.next()\n",
        "inputs2, outputs2 = data2\n",
        "print(inputs2, outputs2)\n",
        "print(inputs2.shape, outputs2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZgHPDJhEPFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this tutorial demoes a simple CNN\n",
        "# https://algorithmia.com/blog/convolutional-neural-nets-in-pytorch\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    \n",
        "    #Our batch shape for input x is (3, 32, 32)\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        #Input channels = 3, output channels = 18\n",
        "        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        #4608 input features, 64 output features (see sizing flow below)\n",
        "        self.fc1 = torch.nn.Linear(18 * 16 * 16, 64)\n",
        "        \n",
        "        #64 input features, 10 output features for our 10 defined classes\n",
        "        self.fc2 = torch.nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #Computes the activation of the first convolution\n",
        "        #Size changes from (3, 32, 32) to (18, 32, 32)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        \n",
        "        #Size changes from (18, 32, 32) to (18, 16, 16)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        #Reshape data to input to the input layer of the neural net\n",
        "        #Size changes from (18, 16, 16) to (1, 4608)\n",
        "        #Recall that the -1 infers this dimension from the other given dimension\n",
        "        x = x.view(-1, 18 * 16 *16)\n",
        "        \n",
        "        #Computes the activation of the first fully connected layer\n",
        "        #Size changes from (1, 4608) to (1, 64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        \n",
        "        #Computes the second fully connected layer (activation applied later)\n",
        "        #Size changes from (1, 64) to (1, 10)\n",
        "        x = self.fc2(x)\n",
        "        return(x)\n",
        "\n",
        "def outputSize(in_size, kernel_size, stride, padding):\n",
        "  output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
        "  return(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoVDOTpHiUlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXK-IVMWUNJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dbd0d1a-8153-4d91-dbae-9048da248619"
      },
      "source": [
        "t = torch.tensor([[1,2], [3, 4]])\n",
        "t\n",
        "print(t.reshape(-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH8ZTgG6UZFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6133e26a-915e-4781-c935-408d9f47b697"
      },
      "source": [
        "t.unsqueeze(dim=0)\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLV5SsbEVFix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d8d206e8-8ed3-4d5a-8a11-77503d8222a2"
      },
      "source": [
        "t = torch.randn(2, 4, 3, dtype=torch.float64) \n",
        "print(t)\n",
        "print(t.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 2.0809,  1.6009,  1.0557],\n",
            "         [ 0.2655, -0.3276,  0.3141],\n",
            "         [ 1.8768,  0.9406,  0.0193],\n",
            "         [-1.1189, -1.9978,  0.9711]],\n",
            "\n",
            "        [[ 1.2631,  1.5536, -0.7883],\n",
            "         [ 1.0088, -0.5322, -2.2212],\n",
            "         [ 0.3917,  0.4168,  0.3823],\n",
            "         [-0.5199, -0.3925, -0.6523]]], dtype=torch.float64)\n",
            "torch.Size([2, 4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hYSp8GgWPlr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "46ad6357-3bd9-4373-9870-d511d6551cc5"
      },
      "source": [
        "x  = t.unsqueeze(2)\n",
        "print(x.size())\n",
        "print(x)\n",
        "y = x.squeeze()\n",
        "print(y.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 4, 1, 3])\n",
            "tensor([[[[ 2.0809,  1.6009,  1.0557]],\n",
            "\n",
            "         [[ 0.2655, -0.3276,  0.3141]],\n",
            "\n",
            "         [[ 1.8768,  0.9406,  0.0193]],\n",
            "\n",
            "         [[-1.1189, -1.9978,  0.9711]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2631,  1.5536, -0.7883]],\n",
            "\n",
            "         [[ 1.0088, -0.5322, -2.2212]],\n",
            "\n",
            "         [[ 0.3917,  0.4168,  0.3823]],\n",
            "\n",
            "         [[-0.5199, -0.3925, -0.6523]]]], dtype=torch.float64)\n",
            "torch.Size([2, 4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxrWNNGSWSiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d2ac8594-4e61-4dce-8272-61aa039cc952"
      },
      "source": [
        "t1 = torch.tensor([1, 1, 1])\n",
        "t2 = torch.tensor([2, 2, 2])\n",
        "t3 = torch.tensor([3, 3,3 ])\n",
        "t = torch.cat((t1, t2, t3))\n",
        "print(t)\n",
        "t = torch.stack((t1, t2, t3))\n",
        "print(t)\n",
        "print((t1.unsqueeze(0), t2.unsqueeze(0), t3.unsqueeze(0)))\n",
        "t = torch.cat((t1.unsqueeze(0), t2.unsqueeze(0), t3.unsqueeze(0)), dim=1)\n",
        "print(t)\n",
        "t = torch.stack((t1.unsqueeze(0), t2.unsqueeze(0), t3.unsqueeze(0)))\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])\n",
            "tensor([[1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3]])\n",
            "(tensor([[1, 1, 1]]), tensor([[2, 2, 2]]), tensor([[3, 3, 3]]))\n",
            "tensor([[1, 1, 1, 2, 2, 2, 3, 3, 3]])\n",
            "tensor([[[1, 1, 1]],\n",
            "\n",
            "        [[2, 2, 2]],\n",
            "\n",
            "        [[3, 3, 3]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDjEsEQ-hqXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}